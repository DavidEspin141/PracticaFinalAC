---
title: "modeloRedNeuronal"
output: html_document
date: "2024-12-01"
---
```{r}
library(caret)
rm(list = ls())
credit<- read.csv("credit+approval/crx.data", header=FALSE,na.strings = "?")
credit.trainIdx<-readRDS("credit.trainIdx.rds")
categoricos_col<-c("V1","V4","V5","V6","V7","V9","V10","V12","V13","V16")
credit[categoricos_col]<-lapply(credit[categoricos_col],FUN = as.factor)
levels(credit$V4)<-c(levels(credit$V4),"t")
credit.Datos.Train<-credit[credit.trainIdx,]
credit.Datos.Test<-credit[-credit.trainIdx,]
nrow(credit.Datos.Train)
nrow(credit.Datos.Test)
credit.varSalida = c("V16")
credit.varsEntrada = setdiff(names(credit), credit.varSalida)
```

Para trabajar con el modelo **nnet**, que representa una red neuronal, 
primero debemos estudiar el modelo, viendo los hiper-parámetros que contiene.

```{r}
modelLookup("nnet")
```

Vemos que **nnet** tiene 2 hiper-parámetros, size y decay, por lo que podremos modificarlos en un futuro.\ 
Para empezar con el entrenamiento, debemos saber que el modelo nnet no procesa datos nulos, es decir, el modelo dará errores si lo entrenamos sin hacer una modificación previa de los datos que tenemos. \ 

Como sabemos que las variables numéricas con valores nulos son V2 y V14,
las procesamos sustituyendo los valores nulos por el valor de la mediana para esa variable.

```{r}
credit.Datos.Train$V2[is.na(credit.Datos.Train$V2)] =
  median(credit.Datos.Train$V2,na.rm = TRUE)
credit.Datos.Train$V14[is.na(credit.Datos.Train$V14)] =
  median(credit.Datos.Train$V14,na.rm = TRUE)
```

Para las variables categóricas hacemos lo mismo pero aplicando los valores nulos a la moda de cada variable.

```{r}
moda = 
  function(x) {
    names(which.max(table(x, useNA = "no")))  
  }
credit.Datos.Train$V1[is.na(credit.Datos.Train$V1)] = 
  moda(credit.Datos.Train$V1)
credit.Datos.Train$V4[is.na(credit.Datos.Train$V4)] = 
  moda(credit.Datos.Train$V4)
credit.Datos.Train$V5[is.na(credit.Datos.Train$V5)] = 
  moda(credit.Datos.Train$V5)
credit.Datos.Train$V6[is.na(credit.Datos.Train$V6)] = 
  moda(credit.Datos.Train$V6)
credit.Datos.Train$V7[is.na(credit.Datos.Train$V7)] = 
  moda(credit.Datos.Train$V7)
```

Tras eliminar los valores nulos ya podemos entrenar el modelo. 
En este hemos usado el parámetro preProcess ya que nnet es muy sensible a las escalas de los valores de entrada, y trace = FALSE por no llenar el terminal de información en cada iteración que se haga en el entrenamiento.\ 


```{r}
eliminar_outliers <- function(df, cols) {
  # Iniciar vector lógico para mantener filas válidas
  rows_to_keep <- rep(TRUE, nrow(df))
  
  for (col in cols) {
    Q1 <- quantile(df[[col]], 0.25, na.rm = TRUE)  # Primer cuartil
    Q3 <- quantile(df[[col]], 0.75, na.rm = TRUE)  # Tercer cuartil
    IQR_val <- Q3 - Q1                             # Rango intercuartílico
    
    # Límites superior e inferior
    lower_bound <- Q1 - 1.5 * IQR_val
    upper_bound <- Q3 + 1.5 * IQR_val
    
    # Identificar filas con valores dentro de los límites
    rows_to_keep <- rows_to_keep & (df[[col]] >= lower_bound & df[[col]] <= upper_bound)
  }
  
  # Filtrar filas válidas y eliminar filas con valores NA
  return(na.omit(df[rows_to_keep, ]))
}



# Identificar columnas numéricas
numeric_cols <- credit.varsEntrada[sapply(credit.Datos.Train[credit.varsEntrada], is.numeric)]

# Eliminar filas con outliers del conjunto de entrenamiento
credit.Datos.Train_Tratar <- eliminar_outliers(credit.Datos.Train, numeric_cols)


library(nnet)
library(caret)

set.seed(1234)
# Entrenando el modelo de red neuronal
tuneGrid <- expand.grid(
  #size = c(1, 2, 5),  # Número de neuronas en la capa oculta
  size = seq(1,10,1),
  decay = c(0.001, 0.01, 0.1,0.5)  # Tasa de regularización L2
)

# Entrenando el modelo de red neuronal
credit.modelo.nnet <- train(
  credit.Datos.Train_Tratar[credit.varsEntrada],    # Datos de entrada
  credit.Datos.Train_Tratar[[credit.varSalida]],    # Variable de salida
  preProcess = c("center", "scale"),  # Preprocesamiento de los datos
  method = "nnet",                            # Usando redes neuronales
  tuneGrid = tuneGrid,                        # Usando la parrilla de parámetros
  maxit = 20,                               # Número máximo de iteraciones
  trace = FALSE,                              # No mostrar el progreso
  skip=TRUE
)
# Ver los resultados del modelo
print(credit.modelo.nnet)


```
```{r}

#Mostrar resultados

pred_red_neuronal = predict(credit.modelo.nnet, 
                       newdata = credit.Datos.Test[credit.varsEntrada])

confMatrix = confusionMatrix(pred_red_neuronal, 
                                     credit.Datos.Test[[credit.varSalida]])

# Mostrar resultados
print(confMatrix)

```

