---
title: "Aprendizaje Computacional: Práctica Final 2024/2025"
author: "Pedro García Montoya, Mario Martínez Turpin y David Espín Jiménez"
output:
  html_document:
    theme: spacelab
    highlight: kate
    df_print: paged
    toc: yes
    toc_float: yes
    number_sections: yes
  pdf_document:
    toc: yes
editor_options:
  markdown:
    wrap: 72
---

# Carga de la base de datos

Con esto comprobamos que hemos cargado de manera correcta la base de
datos.

```{r}
credit<- read.csv("credit+approval/crx.data", header=FALSE)
credit.trainIdx<-readRDS("credit.trainIdx.rds")
credit.Datos.Train<-credit[credit.trainIdx,]
credit.Datos.Test<-credit[-credit.trainIdx,]
nrow(credit.Datos.Train)
nrow(credit.Datos.Test)
```

# Sección 1: Análisis DEA

Antes de ponernos a tratar con los datos y analizar en detalle las
variables como se pide en el enunciado, hemos accedido a la página web
de la base de datos pues esta nos ofrece bastante información sobre el
tipo de datos que estamos tratando.\
Esta base de datos trata con valores relacionados con aplicaciones de
tarjetas de crédito, es por ello por lo que las variables y sus
correspondientes valores están cifrados con valores sin signficado, por
la confidencialidad de datos.\
Para esta práctica vamos a trabajar con el **aprendizaje supervisado**
donde tenemos 15 predictores (V1-V15) y una variable de respuesta $y$
(V16).

Si comprobamos la estructura de nuestra base de datos y la analizamos,
podemos ver como los datos no se han importado de la manera correcta.
Esto lo podemos ver comparando el tipo de dato ofrecido por el comando
`str(credit)` con la información de
\<<https://archive.ics.uci.edu/dataset/27/credit+approval>}

```{r}
str(credit)
```

Podemos ver como las variables categóricas
(V1,V4,V5,V6,V7,V9,V10,V12,V13 y V16) no se han importado como tales,
sino como caracteres (chr). Del mismo modo, V2 que es una variable
numérica no tiene ese tipo de datos. Por tanto, lo primero que debemos
de hacer antes de hacer ningún análisis de las variables es corregir
esto.

```{r}
categoricos_col<-c("V1","V4","V5","V6","V7","V9","V10","V12","V13","V16")
credit[categoricos_col]<-lapply(credit[categoricos_col],FUN = as.factor)
str(credit)
```

Tras aplicar la transformación en los datos para convertirlos en
categóricos, podemos apreciar que algunos de ellos poseen más niveles de
los que aparecen en la página web, esto se debe a que hay algunos que
tienen valores incompletos, por los que también los considera como
nivel. A parte, podemos apreciar que la variable V4, posee 3 niveles (si
descontamos el nivel resultante de los valores incompletos), por lo que
según la información que hay en la página web, nos faltaría un nivel.
Podemos llegar a la conclusión de que este, es un valor que forma parte
del dominio, para este nivel no hay ningún valor que aparezca en los
datos.

A continuación, vamos a observar de mejor forma la división de niveles
con el comando `levels()`.

```{r}
levels(credit$V1)
levels(credit$V4)
levels(credit$V5)
levels(credit$V6)
levels(credit$V7)
```

Con esto apreciamos de mejor forma, que las variables categóricas que
tienen valores nulos son V1,V4,V5,V6 y V7.

Como hemos analizado, nuestra base de datos cuenta con datos missing,
por lo que sería conveniente cargarla de nuevo, pero indicándolo, para
que así se guarden directamente como datos NA y se pueda hacer un
tratamiento correcto de estos datos luego. Además, se hará todo el tratamiento anterior para dejar la base de datos como nos interesa, cn los tipos de datos bien establecidos y los niveles de los mismos.

```{r}
rm(list = ls())
credit<- read.csv("credit+approval/crx.data", header=FALSE,na.strings = "?")
credit.trainIdx<-readRDS("credit.trainIdx.rds")
categoricos_col<-c("V1","V4","V5","V6","V7","V9","V10","V12","V13","V16")
credit[categoricos_col]<-lapply(credit[categoricos_col],FUN = as.factor)
levels(credit$V4)<-c(levels(credit$V4),"t")
credit.Datos.Train<-credit[credit.trainIdx,]
credit.Datos.Test<-credit[-credit.trainIdx,]
nrow(credit.Datos.Train)
nrow(credit.Datos.Test)
```


Una vez hechos los cambios anteriores y antes de pasar a hacer un
análisis monovariable de algunas de las variables, vamos a ver de manera
resumida que información aporta cada variable, así como la cantidad de
datos desconocidos que tiene.

```{r}
summary(credit)
```

Como vemos, nuestros datos cuentan con NAs que habrá que solucionar para
poder hacer un buen modelo a posterior.\
Antes de tratar los NAs, debemos de tratar los datos atípicos que puedan
aparecer en nuestras variables, pues por ejemplo para las numéricas
estos valores atípicos influyen en la representación de su distribución
y por lo tanto podríamos elegir la media para sustituir los NAs cuando
quizás lo prudente sería la mediana.

```{r}
library(gridExtra)
library(ggplot2)
g1<-ggplot(na.omit(credit), aes(x = "", y = V2)) + 
  geom_boxplot() +
  labs(y = "V2", x = "") +
  theme_minimal()
g2<-ggplot(na.omit(credit), aes(x = "", y = V3)) + 
  geom_boxplot() +
  labs(y = "V3", x = "") +
  theme_minimal()
g3<-ggplot(na.omit(credit), aes(x = "", y = V8)) + 
  geom_boxplot() +
  labs(y = "V8", x = "") +
  theme_minimal()
g4<-ggplot(na.omit(credit), aes(x = "", y = V11)) + 
  geom_boxplot() +
  labs(y = "V11", x = "") +
  theme_minimal()
g5<-ggplot(na.omit(credit), aes(x = "", y = V14)) + 
  geom_boxplot() +
  labs(y = "V14", x = "") +
  theme_minimal()
g6<-ggplot(na.omit(credit), aes(x = "", y = V15)) + 
  geom_boxplot() +
  labs(y = "V15", x = "") +
  theme_minimal()
grid.arrange(g1,g2,g3,g4,ncol=2)
grid.arrange(g5,g6)
```

Como vemos, todas las variables numéricas cuentan con outliers. Estos
valores pueden resultar o no un problema, dependiendo del modelo que se
quiera idear, pues algunos como la regresión lineal tienen poca
tolerancia a outliers y otros como randomForest los toleran y tratan de
manera interna.\
Es por ello por lo que esto datos atípicos se solucionarán o no a
posteriori, cuando se haya elegido el modelo.

```{r}
(credit)[!complete.cases(credit),]
colSums(is.na(credit))

```

Con esto podemos ver, que en total contamos con 37 filas de las 690
observaciones totales que forman nuestro `data.frame` que cuentan con
NAs en alguna de sus columnas (predictores). Son las variables
V1,V2,V4,V5,V6,V7 y V14 las que cuentan con NAs. El número de NAs es
bastante pequeño y muy posiblemente lo más fácil sería directamente
eliminar las observaciones que cuentan con NAs de nuestras
observaciones. 
Estas decisiones se tomarán más adelante en función del modelo usado y los requerimientos que este tenga. 


## Análisis monovariable

A continuación, vamos a llevar a cabo el análisis monovariable de
algunas de las variables del conjunto de datos. Para llevar a cabo esto,
el estudio lo vamos a realizar en variables o predictores de distinto
tipo, tanto en alguna númerica como en otra categórica.

En primera instanacia, vamos a comenzar por realizar un estudio
monovariable del predictor "V1", que se trata de un tipo de datos
categórico como hemos visto previamente. De todas formas, vamos a volver
a apreciarlo con porcentajes:

```{r}
porcent  <- prop.table(table(credit$V1)) * 100
cbind(total=table(credit$V1), porcentaje=porcent)
```

En este caso, al tener un tipo de datos categórico, no nos encontramos
con ningún dato fuera de rango o outlayer, ya que los datos están
contenidos en el dominio de los dos niveles disponibles, "a" y "b".

Al no ser de tipo númerico tampoco podemos apreciar una gráfica con la
distribución de los datos y ver a que distribución se aproxima.

A continuación, vamos a analizar el predictor "V2" a fondo, que al
contrario que "V1", este sí que cuenta con datos númericos por lo que
podemos llevar a cabo un estudio más exhaustivo. Comenzamos de igual
forma que antes, apreciando un breve resuemen de la variable a
investigar:

```{r}
summary(credit$V2)
```

En este resumen, apreciamos que la mediana y la media tienen valores un
poco distantes, ya que el valor de la media es mayor debido a los
outliers por encima de la mediana que se encuentran en nuestro data
frame. Debemos de recordar que la mediana es un valor mucho más robusto
y menos suceptible a los outliers que la media, ya que esta última varía
más ante datos atípicos.

Además, en este caso podemos apreciar por medio de un histograma la
distribución que sigue este predictor:

```{r}
#Representamos histograma
myhist = ggplot(data=credit,aes(V2)) +
  geom_histogram(col="orange",fill="orange",alpha=0.2,) + 
  labs(title="Histograma V2", y="Count") 
#Marca el valor de la media con una línea azul vertical
myhist = myhist + geom_vline(xintercept = mean(credit$V2),
                             col="blue")
#Marca el valor de la mediana con una línea roja
myhist = myhist + geom_vline(xintercept = median(credit$V2),
                             col="red")
myhist+geom_rug(data=credit,aes(x=V2,y=0),
           sides="b",position="jitter")
```

Mediante el histograma resultante, podemos apreciar que efectivamente
como hemos mencionado antes, se trata de una distribución normal, aunque en esta podemos apreciar muy claramente que se encuentra sesgada a la
derecha, debido a los outlyers que se encuentran entre los datos. Debido
a la misma razón,ocurre lo mencionado con la media y la mediana.\
Los datos atípicos, los identificamos mejor también gracias al comado
`jitter`, que crea un poco de ruido para poder visualizar de mejor forma
los valores de los datos repetidos (comprobamos que hay ciertos posibles
outliers en la parte derecha del histograma).

Por último vamos a analizar también el predictor "V3", cuyos datos
también son de tipo numérico. Como siempre, empezamos viendo un pequeño
resumen de los datos de la variable:

```{r}
summary(credit$V3)
```

En este caso, apreciamos que al igual que antes, la media y la mediana
difieren bastante entre sí, lo que vuelve a sugerir que haya outliers
entre los datos. A continuación, vamos a apreciar el histograma para
corrobar esta idea:

```{r}
#Representamos histograma
myhist = ggplot(data=credit,aes(V3)) +
  geom_histogram(col="orange",fill="orange",alpha=0.2,) + 
  labs(title="Histograma V3", y="Count") 
#Marca el valor de la media con una línea azul vertical
myhist = myhist + geom_vline(xintercept = mean(credit$V3),
                             col="blue")
#Marca el valor de la mediana con una línea roja
myhist = myhist + geom_vline(xintercept = median(credit$V3),
                             col="red")
myhist+geom_rug(data=credit,aes(x=V3,y=0),
           sides="b",position="jitter")
```

Gracias a `rug` de nuevo, apreciamos que también hay ciertos outliers
entre los datos, además de que el histograma resultante sigue una
distribución exponencial inversa, esto lo sabemos debido a la gran cola
que posee el histograma.

## Análisis multivariable

Por otro lado, vamos a llevar a cabo un estudio multivariable de los
predictores de la base de datos. Para el este, sería muy útil hacer uso
de un análisis de componentes principales, también denominado PCA, sin
embargo, se sabe que este tipo de análisis es muy susceptible a los
outliers, ya que se basa en la varianza, por lo que al todavía no ser
tratados, el PCA es inviable.

Primero, vamos a representar una matriz de correlación mediante el
comando `cor`, lo que nos va a permitir observar que tan relacionados
están entre sí los diversos predictores.

Después vamos a representar mediante el comando `pairs` de forma gráfica
las relaciones entre pares de predictores. A parte, vamos a
representarlo diferenciando los datos entre los diversos valores que
tienen según cada predictor de tipo categórico.

```{r}
cor(credit[, c("V2", "V3", "V8", "V11", "V14", "V15")])
pairs(credit[,c("V2","V3","V8","V11","V14","V15")],col=as.numeric(credit$V1))
pairs(credit[,c("V2","V3","V8","V11","V14","V15")],col=as.numeric(credit$V4))
pairs(credit[,c("V2","V3","V8","V11","V14","V15")],col=as.numeric(credit$V5))
pairs(credit[,c("V2","V3","V8","V11","V14","V15")],col=as.numeric(credit$V6))
pairs(credit[,c("V2","V3","V8","V11","V14","V15")],col=as.numeric(credit$V7))
pairs(credit[,c("V2","V3","V8","V11","V14","V15")],col=as.numeric(credit$V9))
pairs(credit[,c("V2","V3","V8","V11","V14","V15")],col=as.numeric(credit$V10))
pairs(credit[,c("V2","V3","V8","V11","V14","V15")],col=as.numeric(credit$V12))
pairs(credit[,c("V2","V3","V8","V11","V14","V15")],col=as.numeric(credit$V13))
pairs(credit[,c("V2","V3","V8","V11","V14","V15")],col=as.numeric(credit$V16))
```

Tras observar la matriz resultante, podemos observar que no hay una gran
relación entre predictores aunque, entre ellos destacan la relación
entre "V2" y "V8" con un una correlación moderada de 0.39146361; la de
"V8" y "V11", con otra correlación de 0.32232967; y la relación entre
"V2" y "V3" de 0.20217658.

De entre las gráficas, no podemos sacar ninguna relación clara entre
tipos de datos, ya que los datos de los distintos niveles se encuentran
muy juntos. En las gráficas podemos apreciar que las relaciones
previamente mencionadas tienen una forma que, en algunos tramos, simula
una diagonal, lo que es muestra de su mayor nivel de correlación.

## Modelo Rpart

Una vez hecho el análisis previo, se va a comenzar a crear modelos de predicción basados en aprendizaje supervisado. \ 

El modelo simple que vamos a usar en la práctica es Rpart (Recursive 
Partitioning), ya que es una técnica rápida, fácil de interpretar, eficaz y que trabaja con datos categóricos y numéricos, lo que simplifica el preprocesamiento de estos.\ 

Para poder usar el modelo previamente debemos conocer sus hiper-parámetros, para ello usamos `modelLookup()`

```{r}
library(caret)
modelLookup(("rpart"))
```

Vemos que el único hiper-parámetro de este modelo es **cp**, que indica la complejidad del modelo, es decir, controla cuando el algoritmo crece o para de dividirse. \ 

Antes de comenzar a entrenar tenemos que separar los predictores de la 
variable objetivo. \ 

```{r}
credit.varSalida = c("V16")
credit.varsEntrada = setdiff(names(credit), credit.varSalida)
```

Vamos a hacer distintas pruebas con distintos preprocesamientos de datos
para encontrar el mejor resultado posible. \ 

Para comenzar, lo único que haremos es tratar los NAs de los datos de 
entrenamiento para evitar posibles errores ya que `rpart` no procesa
correctamente dichos datos.\ 

Para ello, vamos a investigar en nuestras variables numéricas para ver quédistribución siguen para así decidir si es mejor opción sustituir los NAs por media o mediana.\ 

```{r}
library(ggplot2)
library(gridExtra)
p1 = ggplot(data=credit,aes(sample=V2)) +
  ggtitle("QQ plot para V2") +
  geom_qq() + 
  stat_qq_line() + 
  xlab("Distribución teórica") + ylab("Distribución muestral")
p2 = ggplot(data=credit,aes(sample=V14)) +
  ggtitle("QQ plot para V14") +
  geom_qq() + 
  stat_qq_line() + 
  xlab("Distribución teórica") + ylab("Distribución muestral")

grid.arrange(p1,p2,nrow=2)
```

Como podemos ver en las dos variables numéricas que contienen NAs, V2 sigue una normal cuyos valores se separan de esta en los extremos; en el caso de V14, vemos que está sesgada a la derecha, así que decidimos sustituir los NAs de estas variables por la mediana, ya que consideramos una opción más sólida que la media, ya que esta podría estar desviada debido a los valores altos. \ 

Por otro lado, las variables categóricas tendrán un tratamiento similar,
pero esta vez los NAs los asociaremos a la moda.

Lo primero que vamos a hacer, antes de hacer ningún tratamiento es copiar los datos de la base de datos en una nueva variable, de modo que podamos usar los datos en cada uno de los modelos como queramos, sin necesidad de tener que estar cargando la base de datos todo el rato y perdiendo las variables y modelos calculados. 

```{r}
#Variables numéricas
credit.Datos.Train$V2[is.na(credit.Datos.Train$V2)] =
  median(credit.Datos.Train$V2,na.rm = TRUE)
credit.Datos.Train$V14[is.na(credit.Datos.Train$V14)] =
  median(credit.Datos.Train$V14,na.rm = TRUE)

#Variables categóricas
moda = 
  function(x) {
    names(which.max(table(x, useNA = "no")))  
  }
credit.Datos.Train$V1[is.na(credit.Datos.Train$V1)] = 
  moda(credit.Datos.Train$V1)
credit.Datos.Train$V4[is.na(credit.Datos.Train$V4)] = 
  moda(credit.Datos.Train$V4)
credit.Datos.Train$V5[is.na(credit.Datos.Train$V5)] = 
  moda(credit.Datos.Train$V5)
credit.Datos.Train$V6[is.na(credit.Datos.Train$V6)] = 
  moda(credit.Datos.Train$V6)
credit.Datos.Train$V7[is.na(credit.Datos.Train$V7)] = 
  moda(credit.Datos.Train$V7)

credit.Datos.Train.TratamientoOUT <- credit.Datos.Train

```

Una vez eliminados los NAs de nuestras variables, podemos comenzar a hacer pruebas con el modelo. \ 

La primera prueba que haremos será entrenar el modelo sin preprocesar más los datos, para ver los resultados con los que partimos en este entrenamiento. \ 

```{r}
library(rpart)

set.seed(1234)
credit.modelo.rpart.noPreProc = train(credit.Datos.Train[credit.varsEntrada],
                            credit.Datos.Train[[credit.varSalida]],
                            method='rpart',
                            trControl = trainControl(method = "cv", number = 5))
credit.modelo.rpart.noPreProc
```

Con este entrenamiento podemos ver que, al estudiar la exactitud (Accuracy),nos da valores superiores e inferiores a 85% dependiendo del **cp** que se ha usado.\ 

Ahora vamos a probar tratando los datos atípicos para ver si podemos mejorar el resultado obtenido previamente.

```{r}
#Primero debemos eliminar los outliers
eliminar_outliers = function(df, cols) {
  rows_to_keep = rep(TRUE, nrow(df))
  
  for (col in cols) {
    Q1 = quantile(df[[col]], 0.25, na.rm = TRUE)
    Q3 = quantile(df[[col]], 0.75, na.rm = TRUE)
    InterQ = Q3 - Q1
    
    lower_bound = Q1-1.5*InterQ
    upper_bound = Q3+1.5*InterQ
    
    rows_to_keep = rows_to_keep&(df[[col]] >= lower_bound&df[[col]] 
                                 <= upper_bound)
  }
  
  return(na.omit(df[rows_to_keep, ]))
}

numeric_cols = credit.varsEntrada[sapply(credit.Datos.Train.TratamientoOUT[credit.varsEntrada],
                                         is.numeric)]

credit.Datos.Train.TratamientoOUT = eliminar_outliers(credit.Datos.Train.TratamientoOUT, numeric_cols)

#Ya hemos tratado los datos, ahora volvemos a entrenar el modelo
set.seed(1234)
credit.modelo.rpart.PreProc = train(
              credit.Datos.Train.TratamientoOUT[credit.varsEntrada],
              credit.Datos.Train.TratamientoOUT[[credit.varSalida]],
              method = "rpart",
              trControl = trainControl(method = "cv", number = 5))
credit.modelo.rpart.PreProc

```

Ahora vamos a comparar los dos resultados obtenidos para ver cuál es más
preciso estudiando las predicciones realizadas por los modelos (tratando datos y sin tratarlos) y haciendo matrices para comprobar la efectividad de las pruebas.\ 


```{r}
pred_SinTratar = predict(credit.modelo.rpart.noPreProc, 
                          newdata = credit.Datos.Test[credit.varsEntrada])

confMatrix_SinTratar = confusionMatrix(pred_SinTratar, 
                                       credit.Datos.Test[[credit.varSalida]])

#Mostrar resultados
print(confMatrix_SinTratar)


pred_Tratado = predict(credit.modelo.rpart.PreProc, 
                       newdata = credit.Datos.Test[credit.varsEntrada])

confMatrix_Tratado = confusionMatrix(pred_Tratado, 
                                     credit.Datos.Test[[credit.varSalida]])

# Mostrar resultados
print(confMatrix_Tratado)

```

Como vemos en las matrices que mostramos, el modelo sin preprocesamiento de datos tiene un valor de Accuracy superior al 85% mientras que este valor en el modelo con los datos tratados es cercano al 84%.

# Modelo GBM

Uno de los modelos complejos que vamos a usar en esta práctica es GBM (Stochastic Gradient Boosting).\

Antes de usar el modelo gbm es importante entender a este. Si hacemos uso de `modelLookup()` podemos ver los hiper-parámetros con los que trabaja este modelo.
```{r}
library(caret)
modelLookup(("gbm"))
```
1. El hiper-parámetro **n.trees** controla cuántos árboles se entrenan. Más árboles suelen mejorar el ajuste, pero un exceso puede llevar al sobreajuste. (valor por defecto es 100).\ 
2. El hiper-parámetro **interaction.depth** Determina la complejidad de los árboles.  (valor 1= additive model; valor 2= 2way-directiones).\ 
3. El hiper-parámetro **shrinkage** Controla cuánto contribuye cada árbol al modelo. Valores más bajos requieren más árboles para un buen ajuste. (valor por defecto es 0.1).\ 
4. Finalmente, el hiper-parámetro **n.minobsinnode** Establece el tamaño mínimo de las hojas. Valores altos simplifican el modelo. (número real de observaciones, no el peso total).\ 
Destacar que el modelo `gbm`tiene más hiper-parámetros que los `caret`pone a nuestra disposición.\ 

Una de las ventajas de `gbm`es que es un modelo capaz de tratar con variables numéricas y categóricas.

Una vez hecho este análisis previo, ahora debemos de ajustar los datos de la mejor manera para que este modelo trabaje de manera eficiente.\ 

`gbm`es un modelo que no maneja directamente los datos faltantes, por lo que hay que tratarlos antes de hacer un entrenamiento del modelo.

Para tratar los datos nulos, se ha decidido sustituir estos valores faltantes, pues no sabemos lo que signfican las variables, por lo que eliminar las observaciones que contienen NAs no parece la mejor opción. 

Como se ha visto en la sección anterior, las variables numéricas conviene sustituirlas por la mediana como se ha hecho antes. 

```{r}
library(gbm)
set.seed(1234)
modelo.gbm.SinTratarDatos <- train(
              x = credit.Datos.Train[credit.varsEntrada],
              y = credit.Datos.Train[[credit.varSalida]],
              method = "gbm",
              trControl = trainControl(method = "cv", number = 5),
              verbose = FALSE              
)
modelo.gbm.SinTratarDatos
```

Como el tratamiento de outliers sería el mismo que se ha realizado en el modelo Rpart, lo mejor es usar el conjunto de datos que se ha creado para representar que se han tratado los outliers. 
```{r}
set.seed(1234)
modelo.gbm.TratarDatos <- train(
              x = credit.Datos.Train.TratamientoOUT[credit.varsEntrada],
              y = credit.Datos.Train.TratamientoOUT[[credit.varSalida]],
              method = "gbm",
              trControl = trainControl(method = "cv", number = 5),
              verbose = FALSE              
)
modelo.gbm.TratarDatos
```

Ahora, vamos a comparar el modelo gbm, tanto con tratamiento de outliers como sin él, para ver que da mejores resultados. 
```{r}
# Predicciones para el modelo sin tratar
pred_SinTratar <- predict(modelo.gbm.SinTratarDatos, newdata = credit.Datos.Test[credit.varsEntrada])

# Evaluar desempeño en el conjunto de prueba
confMatrix_SinTratar <- confusionMatrix(pred_SinTratar, credit.Datos.Test[[credit.varSalida]])

# Mostrar resultados
print(confMatrix_SinTratar)
# Predicciones para el modelo con tratamiento de outliers
pred_Tratar <- predict(modelo.gbm.TratarDatos, newdata = credit.Datos.Test[credit.varsEntrada])

# Evaluar desempeño en el conjunto de prueba
confMatrix_Tratar <- confusionMatrix(pred_Tratar, credit.Datos.Test[[credit.varSalida]])

# Mostrar resultados
print(confMatrix_Tratar)

```

Ahora, vamos a explorar hiper-parámetros a trabes de la parrilla de valores, para tratar de buscar una configuración óptima que obtenga mejores resultados.
```{r}
tuneGridBuscarGbm = expand.grid(
  n.trees = seq(100, 1000, by = 100),  # Número de árboles
  interaction.depth = c(1, 3, 5),      # Profundidad del árbol
  shrinkage = c(0.01, 0.1, 0.2),       # Tasa de aprendizaje
  n.minobsinnode = c(10, 20, 30)       # Tamaño mínimo del nodo
)
set.seed(1234)
modelo.gbm.BuscarHiper <- train(
              x = credit.Datos.Train.TratamientoOUT[credit.varsEntrada],
              y = credit.Datos.Train.TratamientoOUT[[credit.varSalida]],
              method = "gbm",
              trControl = trainControl(method = "cv", number = 5),
              tuneGrid = tuneGridBuscarGbm,
              verbose = FALSE              
)
modelo.gbm.BuscarHiper
```
Los resultados que se obtienen con el ajuste de hiper-parámetros son:
```{r}
tuneGridMejoresHiper <- expand.grid(
  n.trees = 200,
  interaction.depth = 1,
  shrinkage = 0.1,
  n.minobsinnode = 30
)

set.seed(1234)
modelo.gbm.Hiper <- train(
              x = credit.Datos.Train.TratamientoOUT[credit.varsEntrada],
              y = credit.Datos.Train.TratamientoOUT[[credit.varSalida]],
              method = "gbm",
              trControl = trainControl(method = "cv", number = 5),
              tuneGrid = tuneGridMejoresHiper,
              verbose = FALSE              
)
modelo.gbm.Hiper
# Predicciones para el modelo sin tratar
predHiper <- predict(modelo.gbm.Hiper, newdata = credit.Datos.Test[credit.varsEntrada])

# Evaluar desempeño en el conjunto de prueba
confMatrixHiper <- confusionMatrix(predHiper, credit.Datos.Test[[credit.varSalida]])

# Mostrar resultados
print(confMatrixHiper)

```
