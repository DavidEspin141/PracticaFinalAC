Qdat2 = quantile(val,cuart)
Qdat2teo = qgeom(cuart,p2)
plot(Qdat2,Qdat2teo)
abline(0,1)
Qdat2 = percentiles(cuart)
Qdat2teo = qgeom(cuart,p2)
plot(Qdat2,Qdat2teo)
abline(0,1)
la puta de tu madre
knitr::opts_chunk$set(echo = TRUE)
install.packages("lattice")
install.packages("https://cran.r-project.org/src/contrib/Archive/nutshell.bbdb/nutshell.bbdb_1.0.tar.gz",
repos = NULL, type="source")
install.packages("https://cran.r-project.org/src/contrib/Archive/nutshell.audioscrobbler/nutshell.audioscrobbler_1.0.tar.gz",
repos = NULL, type="source")
install.packages("https://cran.r-project.org/src/contrib/Archive/nutshell/nutshell_2.0.tar.gz",
repos = NULL, type="source")
#Creamos una variable "n" y la inicializamos con el valor 15
n <- 15
#Preguntamos por su contenido
n
#Ahora le damos el valor 5 (podemos cambiar el sentido del operador)
5 -> n
n
x <- 1
#R es case sensitive
X <- 10
x
#Podemos trabajar con cadenas de caracteres, entrecomillando
name <- "Carmen"
#Podemos concatener comandos
n1 <- 10; n2 <- 100
#Podemos usar reales
m <- 0.5
#Podemos preguntar qué hay definido en nuestra sesión
ls()
#Podemos buscar con patrones
ls(pat = "m")
ls(pat = "^m")
ls.str()
#Podemos crear una tabla con vectores de la misma longitud
M <- data.frame(n1, n2, m)
#Podemos preguntar por la estructura de la tabla
str(M)
#Ahora preguntamos solo por el primer nivel de la estructura
str(M, max.level=-1)
#Ahora preguntamos solo por el primer nivel de la estructura
str(M, max.level=-1)
credit<- read.csv("credit+approval/crx.data", header=FALSE)
credit.trainIdx<-readRDS("credit.trainIdx.rds")
credit.Datos.Train<-credit[credit.trainIdx,]
credit.Datos.Test<-credit[-credit.trainIdx,]
nrow(credit.Datos.Train)
nrow(credit.Datos.Test)
summary(credit)
str(credit)
str(credit)
rm(list = ls())
credit<- read.csv("credit+approval/crx.data", header=FALSE,na.strings = "?")
credit.trainIdx<-readRDS("credit.trainIdx.rds")
categoricos_col<-c("V1","V4","V5","V6","V7","V9","V10","V12","V13","V16")
credit[categoricos_col]<-lapply(credit[categoricos_col],FUN = as.factor)
levels(credit$V4)<-c(levels(credit$V4),"t")
credit.Datos.Train<-credit[credit.trainIdx,]
credit.Datos.Test<-credit[-credit.trainIdx,]
nrow(credit.Datos.Train)
nrow(credit.Datos.Test)
library(caret)
modelLookup(("gbm"))
#Comprobación visual para determinar si los variables numéricas se ajustan a una normal
library(ggplot2)
library(gridExtra)
p1 = ggplot(data=credit,aes(sample=V2)) +
ggtitle("QQ plot para V2") +
geom_qq() +
stat_qq_line() +
xlab("Distribución teórica") + ylab("Distribución muestral")
p2 = ggplot(data=credit,aes(sample=V14)) +
ggtitle("QQ plot para V14") +
geom_qq() +
stat_qq_line() +
xlab("Distribución teórica") + ylab("Distribución muestral")
grid.arrange(p1,p2,nrow=2)
# Función para calcular la moda
moda <- function(x) {
names(which.max(table(x, useNA = "no")))
}
credit.Datos.Train$V1[is.na(credit.Datos.Train$V1)] <-
moda(credit.Datos.Train$V1)
credit.Datos.Train$V4[is.na(credit.Datos.Train$V4)] <-
moda(credit.Datos.Train$V4)
credit.Datos.Train$V5[is.na(credit.Datos.Train$V5)] <-
moda(credit.Datos.Train$V5)
credit.Datos.Train$V6[is.na(credit.Datos.Train$V6)] <-
moda(credit.Datos.Train$V6)
credit.Datos.Train$V7[is.na(credit.Datos.Train$V7)] <-
moda(credit.Datos.Train$V7)
library(caret)
credit.varSalida = c("V16")
credit.varsEntrada = setdiff(names(credit), credit.varSalida)
library(gbm)
set.seed(1234)
modeloSinTratarDatos <- train(
x = credit.Datos.Train[credit.varsEntrada],
y = credit.Datos.Train[[credit.varSalida]],
method = "gbm",
trControl = trainControl(method = "cv", number = 5),
verbose = FALSE
)
modeloSinTratarDatos
eliminar_outliers <- function(df, cols) {
# Iniciar vector lógico para mantener filas válidas
rows_to_keep <- rep(TRUE, nrow(df))
for (col in cols) {
Q1 <- quantile(df[[col]], 0.25, na.rm = TRUE)  # Primer cuartil
Q3 <- quantile(df[[col]], 0.75, na.rm = TRUE)  # Tercer cuartil
IQR_val <- Q3 - Q1                             # Rango intercuartílico
# Límites superior e inferior
lower_bound <- Q1 - 1.5 * IQR_val
upper_bound <- Q3 + 1.5 * IQR_val
# Identificar filas con valores dentro de los límites
rows_to_keep <- rows_to_keep & (df[[col]] >= lower_bound & df[[col]] <= upper_bound)
}
# Filtrar filas válidas y eliminar filas con valores NA
return(na.omit(df[rows_to_keep, ]))
}
# Identificar columnas numéricas
numeric_cols <- credit.varsEntrada[sapply(credit.Datos.Train[credit.varsEntrada], is.numeric)]
# Eliminar filas con outliers del conjunto de entrenamiento
credit.Datos.Train_Tratar <- eliminar_outliers(credit.Datos.Train, numeric_cols)
# Entrenar modelo
set.seed(1234)
modeloTratarDatos <- train(
x = credit.Datos.Train_Tratar[credit.varsEntrada],
y = credit.Datos.Train_Tratar[[credit.varSalida]],
method = "gbm",
trControl = trainControl(method = "cv", number = 5),
verbose = FALSE
)
modeloTratarDatos
# Predicciones para el modelo sin tratar
pred_SinTratar <- predict(modeloSinTratarDatos, newdata = credit.Datos.Test[credit.varsEntrada])
# Evaluar desempeño en el conjunto de prueba
confMatrix_SinTratar <- confusionMatrix(pred_SinTratar, credit.Datos.Test[[credit.varSalida]])
# Mostrar resultados
print(confMatrix_SinTratar)
# Predicciones para el modelo con tratamiento de outliers
pred_Tratar <- predict(modeloTratarDatos, newdata = credit.Datos.Test[credit.varsEntrada])
# Evaluar desempeño en el conjunto de prueba
confMatrix_Tratar <- confusionMatrix(pred_Tratar, credit.Datos.Test[[credit.varSalida]])
# Mostrar resultados
print(confMatrix_Tratar)
tuneGridBuscar = expand.grid(
n.trees = seq(100, 1000, by = 100),  # Número de árboles
interaction.depth = c(1, 3, 5),      # Profundidad del árbol
shrinkage = c(0.01, 0.1, 0.2),       # Tasa de aprendizaje
n.minobsinnode = c(10, 20, 30)       # Tamaño mínimo del nodo
)
set.seed(1234)
modeloBuscarHiper <- train(
x = credit.Datos.Train_Tratar[credit.varsEntrada],
y = credit.Datos.Train_Tratar[[credit.varSalida]],
method = "gbm",
trControl = trainControl(method = "cv", number = 5),
tuneGrid = tuneGridBuscar,
verbose = FALSE
)
modeloBuscarHiper
tuneGridMejoresHiper <- expand.grid(
n.trees = 500,
interaction.depth = 3,
shrinkage = 0.01,
n.minobsinnode = 20
)
set.seed(1234)
modeloHiper <- train(
x = credit.Datos.Train_Tratar[credit.varsEntrada],
y = credit.Datos.Train_Tratar[[credit.varSalida]],
method = "gbm",
trControl = trainControl(method = "cv", number = 5),
tuneGrid = tuneGridMejoresHiper,
verbose = FALSE
)
modeloHiper
# Predicciones para el modelo sin tratar
predHiper <- predict(modeloHiper, newdata = credit.Datos.Test[credit.varsEntrada])
# Evaluar desempeño en el conjunto de prueba
confMatrixHiper <- confusionMatrix(predHiper, credit.Datos.Test[[credit.varSalida]])
# Mostrar resultados
print(confMatrixHiper)
rm(list = ls())
credit<- read.csv("credit+approval/crx.data", header=FALSE,na.strings = "?")
credit.trainIdx<-readRDS("credit.trainIdx.rds")
categoricos_col<-c("V1","V4","V5","V6","V7","V9","V10","V12","V13","V16")
credit[categoricos_col]<-lapply(credit[categoricos_col],FUN = as.factor)
levels(credit$V4)<-c(levels(credit$V4),"t")
credit.Datos.Train<-credit[credit.trainIdx,]
credit.Datos.Test<-credit[-credit.trainIdx,]
nrow(credit.Datos.Train)
nrow(credit.Datos.Test)
library(caret)
modelLookup(("gbm"))
#Comprobación visual para determinar si los variables numéricas se ajustan a una normal
library(ggplot2)
library(gridExtra)
p1 = ggplot(data=credit,aes(sample=V2)) +
ggtitle("QQ plot para V2") +
geom_qq() +
stat_qq_line() +
xlab("Distribución teórica") + ylab("Distribución muestral")
p2 = ggplot(data=credit,aes(sample=V14)) +
ggtitle("QQ plot para V14") +
geom_qq() +
stat_qq_line() +
xlab("Distribución teórica") + ylab("Distribución muestral")
grid.arrange(p1,p2,nrow=2)
credit.Datos.Train$V2[is.na(credit.Datos.Train$V2)] <-
median(credit.Datos.Train$V2,na.rm = TRUE)
credit.Datos.Train$V14[is.na(credit.Datos.Train$V14)] <-
median(credit.Datos.Train$V14,na.rm = TRUE)
# Función para calcular la moda
moda <- function(x) {
names(which.max(table(x, useNA = "no")))
}
credit.Datos.Train$V1[is.na(credit.Datos.Train$V1)] <-
moda(credit.Datos.Train$V1)
credit.Datos.Train$V4[is.na(credit.Datos.Train$V4)] <-
moda(credit.Datos.Train$V4)
credit.Datos.Train$V5[is.na(credit.Datos.Train$V5)] <-
moda(credit.Datos.Train$V5)
credit.Datos.Train$V6[is.na(credit.Datos.Train$V6)] <-
moda(credit.Datos.Train$V6)
credit.Datos.Train$V7[is.na(credit.Datos.Train$V7)] <-
moda(credit.Datos.Train$V7)
library(caret)
credit.varSalida = c("V16")
credit.varsEntrada = setdiff(names(credit), credit.varSalida)
library(gbm)
set.seed(1234)
modeloSinTratarDatos <- train(
x = credit.Datos.Train[credit.varsEntrada],
y = credit.Datos.Train[[credit.varSalida]],
method = "gbm",
trControl = trainControl(method = "cv", number = 5),
verbose = FALSE
)
modeloSinTratarDatos
eliminar_outliers <- function(df, cols) {
# Iniciar vector lógico para mantener filas válidas
rows_to_keep <- rep(TRUE, nrow(df))
for (col in cols) {
Q1 <- quantile(df[[col]], 0.25, na.rm = TRUE)  # Primer cuartil
Q3 <- quantile(df[[col]], 0.75, na.rm = TRUE)  # Tercer cuartil
IQR_val <- Q3 - Q1                             # Rango intercuartílico
# Límites superior e inferior
lower_bound <- Q1 - 1.5 * IQR_val
upper_bound <- Q3 + 1.5 * IQR_val
# Identificar filas con valores dentro de los límites
rows_to_keep <- rows_to_keep & (df[[col]] >= lower_bound & df[[col]] <= upper_bound)
}
# Filtrar filas válidas y eliminar filas con valores NA
return(na.omit(df[rows_to_keep, ]))
}
# Identificar columnas numéricas
numeric_cols <- credit.varsEntrada[sapply(credit.Datos.Train[credit.varsEntrada], is.numeric)]
# Eliminar filas con outliers del conjunto de entrenamiento
credit.Datos.Train_Tratar <- eliminar_outliers(credit.Datos.Train, numeric_cols)
# Entrenar modelo
set.seed(1234)
modeloTratarDatos <- train(
x = credit.Datos.Train_Tratar[credit.varsEntrada],
y = credit.Datos.Train_Tratar[[credit.varSalida]],
method = "gbm",
trControl = trainControl(method = "cv", number = 5),
verbose = FALSE
)
modeloTratarDatos
# Predicciones para el modelo sin tratar
pred_SinTratar <- predict(modeloSinTratarDatos, newdata = credit.Datos.Test[credit.varsEntrada])
# Evaluar desempeño en el conjunto de prueba
confMatrix_SinTratar <- confusionMatrix(pred_SinTratar, credit.Datos.Test[[credit.varSalida]])
# Mostrar resultados
print(confMatrix_SinTratar)
# Predicciones para el modelo con tratamiento de outliers
pred_Tratar <- predict(modeloTratarDatos, newdata = credit.Datos.Test[credit.varsEntrada])
# Evaluar desempeño en el conjunto de prueba
confMatrix_Tratar <- confusionMatrix(pred_Tratar, credit.Datos.Test[[credit.varSalida]])
# Mostrar resultados
print(confMatrix_Tratar)
tuneGridBuscar = expand.grid(
n.trees = seq(100, 1000, by = 100),  # Número de árboles
interaction.depth = c(1, 3, 5),      # Profundidad del árbol
shrinkage = c(0.01, 0.1, 0.2),       # Tasa de aprendizaje
n.minobsinnode = c(10, 20, 30)       # Tamaño mínimo del nodo
)
set.seed(1234)
modeloBuscarHiper <- train(
x = credit.Datos.Train_Tratar[credit.varsEntrada],
y = credit.Datos.Train_Tratar[[credit.varSalida]],
method = "gbm",
trControl = trainControl(method = "cv", number = 5),
tuneGrid = tuneGridBuscar,
verbose = FALSE
)
modeloBuscarHiper
tuneGridMejoresHiper <- expand.grid(
n.trees = 200,
interaction.depth = 1,
shrinkage = 0.1,
n.minobsinnode = 30
)
set.seed(1234)
modeloHiper <- train(
x = credit.Datos.Train_Tratar[credit.varsEntrada],
y = credit.Datos.Train_Tratar[[credit.varSalida]],
method = "gbm",
trControl = trainControl(method = "cv", number = 5),
tuneGrid = tuneGridMejoresHiper,
verbose = FALSE
)
modeloHiper
# Predicciones para el modelo sin tratar
predHiper <- predict(modeloHiper, newdata = credit.Datos.Test[credit.varsEntrada])
# Evaluar desempeño en el conjunto de prueba
confMatrixHiper <- confusionMatrix(predHiper, credit.Datos.Test[[credit.varSalida]])
# Mostrar resultados
print(confMatrixHiper)
setwd("~/Escritorio/AC/PracticaFinal")
rm(list = ls())
credit<- read.csv("credit+approval/crx.data", header=FALSE,na.strings = "?")
credit.trainIdx<-readRDS("credit.trainIdx.rds")
categoricos_col<-c("V1","V4","V5","V6","V7","V9","V10","V12","V13","V16")
credit[categoricos_col]<-lapply(credit[categoricos_col],FUN = as.factor)
levels(credit$V4)<-c(levels(credit$V4),"t")
credit.Datos.Train<-credit[credit.trainIdx,]
credit.Datos.Test<-credit[-credit.trainIdx,]
nrow(credit.Datos.Train)
nrow(credit.Datos.Test)
tuneGridMejoresHiper <- expand.grid(
n.trees = 200,
interaction.depth = 1,
shrinkage = 0.1,
n.minobsinnode = 30
)
set.seed(1234)
modeloHiper <- train(
x = credit.Datos.Train_Tratar[credit.varsEntrada],
y = credit.Datos.Train_Tratar[[credit.varSalida]],
method = "gbm",
trControl = trainControl(method = "repeatedcv", number = 5,repeats = 3),
tuneGrid = tuneGridMejoresHiper,
verbose = FALSE
)
rm(list = ls())
credit<- read.csv("credit+approval/crx.data", header=FALSE,na.strings = "?")
credit.trainIdx<-readRDS("credit.trainIdx.rds")
categoricos_col<-c("V1","V4","V5","V6","V7","V9","V10","V12","V13","V16")
credit[categoricos_col]<-lapply(credit[categoricos_col],FUN = as.factor)
levels(credit$V4)<-c(levels(credit$V4),"t")
credit.Datos.Train<-credit[credit.trainIdx,]
credit.Datos.Test<-credit[-credit.trainIdx,]
nrow(credit.Datos.Train)
nrow(credit.Datos.Test)
library(caret)
modelLookup(("gbm"))
#Comprobación visual para determinar si los variables numéricas se ajustan a una normal
library(ggplot2)
library(gridExtra)
p1 = ggplot(data=credit,aes(sample=V2)) +
ggtitle("QQ plot para V2") +
geom_qq() +
stat_qq_line() +
xlab("Distribución teórica") + ylab("Distribución muestral")
p2 = ggplot(data=credit,aes(sample=V14)) +
ggtitle("QQ plot para V14") +
geom_qq() +
stat_qq_line() +
xlab("Distribución teórica") + ylab("Distribución muestral")
grid.arrange(p1,p2,nrow=2)
credit.Datos.Train$V2[is.na(credit.Datos.Train$V2)] <-
median(credit.Datos.Train$V2,na.rm = TRUE)
credit.Datos.Train$V14[is.na(credit.Datos.Train$V14)] <-
median(credit.Datos.Train$V14,na.rm = TRUE)
# Función para calcular la moda
moda <- function(x) {
names(which.max(table(x, useNA = "no")))
}
credit.Datos.Train$V1[is.na(credit.Datos.Train$V1)] <-
moda(credit.Datos.Train$V1)
credit.Datos.Train$V4[is.na(credit.Datos.Train$V4)] <-
moda(credit.Datos.Train$V4)
credit.Datos.Train$V5[is.na(credit.Datos.Train$V5)] <-
moda(credit.Datos.Train$V5)
credit.Datos.Train$V6[is.na(credit.Datos.Train$V6)] <-
moda(credit.Datos.Train$V6)
credit.Datos.Train$V7[is.na(credit.Datos.Train$V7)] <-
moda(credit.Datos.Train$V7)
library(caret)
credit.varSalida = c("V16")
credit.varsEntrada = setdiff(names(credit), credit.varSalida)
library(gbm)
set.seed(1234)
modeloSinTratarDatos <- train(
x = credit.Datos.Train[credit.varsEntrada],
y = credit.Datos.Train[[credit.varSalida]],
method = "gbm",
trControl = trainControl(method = "cv", number = 5),
verbose = FALSE
)
modeloSinTratarDatos
eliminar_outliers <- function(df, cols) {
# Iniciar vector lógico para mantener filas válidas
rows_to_keep <- rep(TRUE, nrow(df))
for (col in cols) {
Q1 <- quantile(df[[col]], 0.25, na.rm = TRUE)  # Primer cuartil
Q3 <- quantile(df[[col]], 0.75, na.rm = TRUE)  # Tercer cuartil
IQR_val <- Q3 - Q1                             # Rango intercuartílico
# Límites superior e inferior
lower_bound <- Q1 - 1.5 * IQR_val
upper_bound <- Q3 + 1.5 * IQR_val
# Identificar filas con valores dentro de los límites
rows_to_keep <- rows_to_keep & (df[[col]] >= lower_bound & df[[col]] <= upper_bound)
}
# Filtrar filas válidas y eliminar filas con valores NA
return(na.omit(df[rows_to_keep, ]))
}
# Identificar columnas numéricas
numeric_cols <- credit.varsEntrada[sapply(credit.Datos.Train[credit.varsEntrada], is.numeric)]
# Eliminar filas con outliers del conjunto de entrenamiento
credit.Datos.Train_Tratar <- eliminar_outliers(credit.Datos.Train, numeric_cols)
# Entrenar modelo
set.seed(1234)
modeloTratarDatos <- train(
x = credit.Datos.Train_Tratar[credit.varsEntrada],
y = credit.Datos.Train_Tratar[[credit.varSalida]],
method = "gbm",
trControl = trainControl(method = "cv", number = 5),
verbose = FALSE
)
modeloTratarDatos
# Predicciones para el modelo sin tratar
pred_SinTratar <- predict(modeloSinTratarDatos, newdata = credit.Datos.Test[credit.varsEntrada])
# Evaluar desempeño en el conjunto de prueba
confMatrix_SinTratar <- confusionMatrix(pred_SinTratar, credit.Datos.Test[[credit.varSalida]])
# Mostrar resultados
print(confMatrix_SinTratar)
# Predicciones para el modelo con tratamiento de outliers
pred_Tratar <- predict(modeloTratarDatos, newdata = credit.Datos.Test[credit.varsEntrada])
# Evaluar desempeño en el conjunto de prueba
confMatrix_Tratar <- confusionMatrix(pred_Tratar, credit.Datos.Test[[credit.varSalida]])
# Mostrar resultados
print(confMatrix_Tratar)
tuneGridBuscar = expand.grid(
n.trees = seq(100, 1000, by = 100),  # Número de árboles
interaction.depth = c(1, 3, 5),      # Profundidad del árbol
shrinkage = c(0.01, 0.1, 0.2),       # Tasa de aprendizaje
n.minobsinnode = c(10, 20, 30)       # Tamaño mínimo del nodo
)
set.seed(1234)
modeloBuscarHiper <- train(
x = credit.Datos.Train_Tratar[credit.varsEntrada],
y = credit.Datos.Train_Tratar[[credit.varSalida]],
method = "gbm",
trControl = trainControl(method = "cv", number = 5),
tuneGrid = tuneGridBuscar,
verbose = FALSE
)
modeloBuscarHiper
tuneGridMejoresHiper <- expand.grid(
n.trees = 200,
interaction.depth = 1,
shrinkage = 0.1,
n.minobsinnode = 30
)
set.seed(1234)
modeloHiper <- train(
x = credit.Datos.Train_Tratar[credit.varsEntrada],
y = credit.Datos.Train_Tratar[[credit.varSalida]],
method = "gbm",
trControl = trainControl(method = "repeatedcv", number = 5,repeats = 3),
tuneGrid = tuneGridMejoresHiper,
verbose = FALSE
)
modeloHiper
# Predicciones para el modelo sin tratar
predHiper <- predict(modeloHiper, newdata = credit.Datos.Test[credit.varsEntrada])
# Evaluar desempeño en el conjunto de prueba
confMatrixHiper <- confusionMatrix(predHiper, credit.Datos.Test[[credit.varSalida]])
# Mostrar resultados
print(confMatrixHiper)
tuneGridMejoresHiper <- expand.grid(
n.trees = 200,
interaction.depth = 1,
shrinkage = 0.1,
n.minobsinnode = 30
)
set.seed(1234)
modeloHiper <- train(
x = credit.Datos.Train_Tratar[credit.varsEntrada],
y = credit.Datos.Train_Tratar[[credit.varSalida]],
method = "gbm",
trControl = trainControl(method = "cv", number = 5),
tuneGrid = tuneGridMejoresHiper,
verbose = FALSE
)
modeloHiper
# Predicciones para el modelo sin tratar
predHiper <- predict(modeloHiper, newdata = credit.Datos.Test[credit.varsEntrada])
# Evaluar desempeño en el conjunto de prueba
confMatrixHiper <- confusionMatrix(predHiper, credit.Datos.Test[[credit.varSalida]])
# Mostrar resultados
print(confMatrixHiper)
